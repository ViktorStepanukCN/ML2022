{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c052172e",
   "metadata": {},
   "source": [
    "# Custom loss function\n",
    "\n",
    "Keras allows us to use custom objects, one of them is ability to implement custom loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d584ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b84ce7",
   "metadata": {},
   "source": [
    "## Huber loss function\n",
    "\n",
    "Huber loss could be used for regression tasks, just like MSE.\n",
    "\n",
    "It is less sensitive to outliers in data because it is quadratic for small values and linear for the big ones.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Huber_loss\n",
    "\n",
    "$L_\\delta(a) = \\left\\{ \\begin{array}{ccc} \\frac{1}{2}a^2 & for |a|\\le \\delta\\\\\n",
    "\\delta(|a| - \\frac{1}{2}\\delta), & otherwise\\end{array} \\right\\}$\n",
    "\n",
    "It is important to set good value for $\\delta$ threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a22c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_huber_loss(error, delta):\n",
    "    # is an absolute value of an error smaller than threshold?\n",
    "    is_small_error = np.abs(error) <= delta\n",
    "    # quadratic branch for smaller errors\n",
    "    small_error_loss = 0.5 * np.square(error)\n",
    "    # linear branch for greater errors\n",
    "    big_error_loss = delta * (np.abs(error) - (0.5*delta))\n",
    "    # returns values in this manner - (condition, true, false)\n",
    "    return np.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efee8e1",
   "metadata": {},
   "source": [
    "Exploring results with different delta thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb326619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of values from <-4, 4) iterate by 0.1\n",
    "x = np.arange(-4, 4, 0.1)\n",
    "\n",
    "# plot loss values\n",
    "plt.title('Huber loss')\n",
    "plt.plot(x, plain_huber_loss(x, 0.1), label='δ = 0.1')\n",
    "plt.plot(x, plain_huber_loss(x, 0.5), label='δ = 0.5')\n",
    "plt.plot(x, plain_huber_loss(x, 1), label='δ = 1')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5275d",
   "metadata": {},
   "source": [
    "## Testing data\n",
    "\n",
    "To keep example simple as possible, I will create array of numbers from -1 to 9 as **x** and set relation with **y** by $y = 2x-1$. So for `x=20` we should get `y=39`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1990612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs - arange takes parameters start, stop, step, so iterate by 1 from -1 to 10\n",
    "x = np.arange(-1, 10, 1).astype('float32')\n",
    "print(f'x: {x}')\n",
    "# label formula\n",
    "y = x * 2 - 1\n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c737b",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "It is just a linear function, so we are OK with neural network with just one fully connected unit with linear activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076676b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(1,))\n",
    "output_layer = Dense(1)(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba125a30",
   "metadata": {},
   "source": [
    "## Using build in loss function\n",
    "\n",
    "For start we just set up model for using mean squared error loss function using stochastic gradient descent optimizer and we will train model for 500 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb39e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_mse_loss = Model(inputs=input_layer, outputs=output_layer)\n",
    "model_mse_loss.summary()\n",
    "model_mse_loss.compile(optimizer='sgd', loss='mse')\n",
    "history = model_mse_loss.fit(x, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b1cab4",
   "metadata": {},
   "source": [
    "Plotting loss function during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce357f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('MSE loss')\n",
    "plt.plot(history.history['loss'], label='MSE loss')\n",
    "plt.legend()\n",
    "plt.ylim([0, 2])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88450b9",
   "metadata": {},
   "source": [
    "Predicting test value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mse_loss.predict([20.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657169c",
   "metadata": {},
   "source": [
    "Get coefficients for **weight** and **bias**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d82e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mse_loss.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db39ca",
   "metadata": {},
   "source": [
    "## Define custom Huber loss\n",
    "\n",
    "For the first case of custom loss we will hard code threshold.\n",
    "\n",
    "We will use TensorFlow functions in these cases because we are working with TF tensors. I will talk more about them later, for now it is just enough to know they are kind of equivalent for numpy operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_true, y_pred):\n",
    "    # hardcoded threshold value\n",
    "    threshold = 1\n",
    "    # get an error between label and prediction\n",
    "    error = y_true - y_pred\n",
    "    # is the error smaller than threshold delta?\n",
    "    is_small_error = tf.abs(error) <= threshold\n",
    "    # quadratic values for smaller errors\n",
    "    small_error_loss = 0.5 * tf.square(error)\n",
    "    # linear part for bigger than threshold\n",
    "    big_error_loss = threshold * (tf.abs(error) - (0.5*threshold))\n",
    "    # if it is a small error, return small error loss, big error loss otherwise\n",
    "    return tf.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08fcd3d",
   "metadata": {},
   "source": [
    "Model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf113a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# we need to define layers again, so it will not work with pre-trained weights from previous MSE model\n",
    "input_layer = Input(shape=(1,))\n",
    "output_layer = Dense(1)(input_layer)\n",
    "model_huber_loss = Model(inputs=input_layer, outputs=output_layer)\n",
    "# loss='huber_loss' would also work\n",
    "model_huber_loss.compile(optimizer='sgd', loss=huber_loss)\n",
    "history = model_huber_loss.fit(x, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d63d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Huber loss with hard coded threshold')\n",
    "plt.plot(history.history['loss'], label='Huber loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8e6ba",
   "metadata": {},
   "source": [
    "Predicting test value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edbfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_huber_loss.predict([[20.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb061ca",
   "metadata": {},
   "source": [
    "Get coefficients for **weight** and **bias**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_huber_loss.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998b6ba3",
   "metadata": {},
   "source": [
    "## Hyperparameter for Huber loss\n",
    "\n",
    "As we saw, just setting arbitrary value can produce worse result than standard MSE. One thing we can do is to allow user to configure delta as a hyperparameter (parameters of network that needs to be set by user, not by training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bee3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function that accepts the hyperparameter\n",
    "def my_huber_loss_with_threshold(threshold):\n",
    "  \n",
    "    # the same error loss as before in closure\n",
    "    def my_huber_loss(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        # using threshold value from wrapper\n",
    "        is_small_error = tf.abs(error) <= threshold\n",
    "        small_error_loss = 0.5 * tf.square(error)\n",
    "        big_error_loss = threshold * (tf.abs(error) - (0.5*threshold))        \n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss) \n",
    "\n",
    "    # return the inner function with set hyperparameter\n",
    "    return my_huber_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe7abd",
   "metadata": {},
   "source": [
    "Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f11d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "input_layer = Input(shape=(1,))\n",
    "output_layer = Dense(1)(input_layer)\n",
    "model_huber_loss_threshold = Model(inputs=input_layer, outputs=output_layer)\n",
    "# now I can set threshold value!\n",
    "model_huber_loss_threshold.compile(optimizer='sgd', loss=my_huber_loss_with_threshold(threshold=1.2))\n",
    "history = model_huber_loss_threshold.fit(x, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cba871",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Huber loss with threshold as a hyperparameter')\n",
    "plt.plot(history.history['loss'], label='Huber loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906009e",
   "metadata": {},
   "source": [
    "Predicting test value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d03372",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_huber_loss_threshold.predict([20.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a17cb",
   "metadata": {},
   "source": [
    "Get coefficients for **weight** and **bias**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_huber_loss_threshold.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8b16bb",
   "metadata": {},
   "source": [
    "## Implement custom loss as a class\n",
    "\n",
    "We can implement loss function as a class by inheriting from Keras Loss class.\n",
    "\n",
    "In that case we need implement `call` function that calculates loss function value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d033d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "# inheriting from Loss class\n",
    "class MyHuberLoss(Loss):  \n",
    "    # we set threshold in constructor\n",
    "    def __init__(self, threshold=1):\n",
    "        super().__init__()        \n",
    "        self.threshold = threshold\n",
    "\n",
    "    # body of a function is the same as before\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= self.threshold\n",
    "        small_error_loss = 0.5 * tf.square(error)\n",
    "        big_error_loss = self.threshold * (tf.abs(error) - (0.5 * self.threshold))        \n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "input_layer = Input(shape=(1,))\n",
    "output_layer = Dense(1)(input_layer)\n",
    "model_huber_class_loss = Model(inputs=input_layer, outputs=output_layer)\n",
    "model_huber_class_loss.compile(optimizer='sgd', loss=MyHuberLoss(threshold=0.7))\n",
    "history = model_huber_class_loss.fit(x, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb48a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Huber loss in a class')\n",
    "plt.plot(history.history['loss'], label='Huber loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b5da3b",
   "metadata": {},
   "source": [
    "Predicting test value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a7481",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_huber_class_loss.predict([20.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c1bb3",
   "metadata": {},
   "source": [
    "Get coefficients for **weight** and **bias**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_huber_loss_threshold.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d160b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
