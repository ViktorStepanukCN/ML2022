{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f54246f",
   "metadata": {},
   "source": [
    "# Keras preprocessing layers\n",
    "\n",
    "There is usually need to preprocess data for neural network.\n",
    "\n",
    "So far we were using preprocessing done ahead using Python script and transforming data using NumPy or Pandas\n",
    "\n",
    "We also did preprocessing on the fly on tf.data.Dataset using map function.\n",
    "\n",
    "Another approach is including preprocessing layers directly inside the model.\n",
    "\n",
    "This is benefical becasue you are preprocessing data on the fly and model preprocesses data the same way during training and production.\n",
    "\n",
    "https://keras.io/api/layers/preprocessing_layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import datasets, layers\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d1338",
   "metadata": {},
   "source": [
    "Load data for preprocessing demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "COLUMN_NAMES = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    URL, \n",
    "    names=COLUMN_NAMES,\n",
    "    na_values='?', \n",
    "    sep=' ',\n",
    "    comment='\\t',  \n",
    "    skipinitialspace=True)\n",
    "\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac = 0.8, random_state = 42)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e066500",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271317f",
   "metadata": {},
   "source": [
    "### Normalization layer\n",
    "\n",
    "Standardize inputs by calling adapt function.\n",
    "\n",
    "It is possible to set mean and variance by hand as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer = tf.keras.layers.Normalization()\n",
    "# you don't need to pass whole dataset to adapt. It could be enought to put big enough randomly sampled data.\n",
    "norm_layer.adapt(train_dataset)\n",
    "norm_layer(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e3463",
   "metadata": {},
   "source": [
    "Setting normalization layers eliminates risk of data pre-processing mismatch.\n",
    "\n",
    "It also computes the normalization using GPU instead of CPU, co it can run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(7,))\n",
    "x = norm_layer(input_layer)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "output_layer = tf.keras.layers.Dense(1)(x)\n",
    "model = Model(inputs = input_layer, outputs = output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f62f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(), metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f2910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, \n",
    "    epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4b4cb",
   "metadata": {},
   "source": [
    "The preprocessing works with tf.data.Dataset as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_dataset, train_labels)).batch(5)\n",
    "dataset = dataset.map(lambda X, y: (norm_layer(X), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69960029",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f6a163",
   "metadata": {},
   "source": [
    "## Image Preprocessing Layers\n",
    "\n",
    "Preprocessing layers for image inputs.\n",
    "\n",
    "### Rescaling layer\n",
    "\n",
    "Rescales the pixel values.\n",
    "\n",
    "* scale: scale to apply on inputs - 1/255 will scale [0, 255] to [0, 1]\n",
    "* offset: the offset - if you would like to have new scale from [-1, 1] - you should use 2/255 with offset -1\n",
    "\n",
    "https://keras.io/api/layers/preprocessing_layers/image_preprocessing/rescaling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cifar10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Rescaling(1.0 / 255)\n",
    "x(train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c06ed9",
   "metadata": {},
   "source": [
    "### Resizing layer\n",
    "\n",
    "Resize images on input.\n",
    "\n",
    "https://keras.io/api/layers/preprocessing_layers/image_preprocessing/resizing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c2775",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Resizing(224, 224)\n",
    "x(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(x(train_images[0])/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f7332",
   "metadata": {},
   "source": [
    "## Image augmentation\n",
    "\n",
    "Data augmentation is a regularization technique that artificially increases the size of the training set by generating multiple variants of single training instance.\n",
    "\n",
    "Augmentation could help overfitting.\n",
    "\n",
    "Augmented data should be as realistic looking as possible (human should not be able to tell which of the data has been made artifically).\n",
    "\n",
    "Augmentation forces the model to learn general patterns by introducing variations in the position, orientation or size of the objects.\n",
    "\n",
    "Listed transformation layers are active only during the training, randomly apply some transformation to batch of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eead594",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f34d24",
   "metadata": {},
   "source": [
    "### RandomRotation\n",
    "\n",
    "Randomly rotates images during training.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594467ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor is fraction of 2Pi - 360Â° degrees\n",
    "# could be a scalar or tuple of size 2 representing lower and upper bound for rotating clockwise and counter-clockwise\n",
    "x = tf.keras.layers.RandomRotation(factor=0.05, seed=42)\n",
    "X_train_scaled = x(train_images[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f576ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # rotated pictures do not use ints for color mapping, so you need to either crop the decimals or normalize it\n",
    "    # to 0-1 for matplotlib to be able to display them\n",
    "    plt.imshow(X_train_scaled[i]/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11418df",
   "metadata": {},
   "source": [
    "### RandomFlip\n",
    "\n",
    "Randomly flip each image horizontally and/or vertically.\n",
    "\n",
    "https://keras.io/api/layers/preprocessing_layers/image_preprocessing/random_flip/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a1bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=42)\n",
    "X_train_scaled = x(train_images[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b46915",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train_scaled[i]/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b14b34",
   "metadata": {},
   "source": [
    "### RandomContrast\n",
    "\n",
    "Randomly adjusts contrast during training - can simulate worse light conditions.\n",
    "\n",
    "https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_contrast/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.RandomContrast(factor=0.8, seed=42)\n",
    "X_train_scaled = x(train_images[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6089b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train_scaled[i]/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4074c50",
   "metadata": {},
   "source": [
    "### RandomZoom\n",
    "\n",
    "Randomly zoom each image during training.\n",
    "\n",
    "https://keras.io/api/layers/preprocessing_layers/image_preprocessing/random_zoom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf524ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.RandomZoom(height_factor=(0.5), width_factor=(0.5), seed=42)\n",
    "X_train_scaled = x(train_images[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e153e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train_scaled[i]/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43317add",
   "metadata": {},
   "source": [
    "### Using augmentations in model\n",
    "\n",
    "We can either use the the preprocessing in the model or using tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f12763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=42),\n",
    "    tf.keras.layers.RandomRotation(factor=0.05, seed=42),\n",
    "    tf.keras.layers.RandomContrast(factor=0.2, seed=42)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8375f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "x = data_augmentation(input_layer)\n",
    "x = layers.Rescaling(1.0 / 255)(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs = input_layer, outputs = output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79725a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=3, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2406af",
   "metadata": {},
   "source": [
    "### Using augmentations on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "dataset = dataset.batch(32).map(lambda x, y: (data_augmentation(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff09599",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "x = layers.Rescaling(1.0 / 255)(input_layer)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs = input_layer, outputs = output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184edfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=3, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66875089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
