{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9765e9",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "Launching a big model training could be like step into unknown territory. \n",
    "\n",
    "You don't know what learning rate is the best or for how many epochs you should train. Doing dry run and than running the whole training again just to stop before best weights is wasteful.\n",
    "\n",
    "Keras provides multiple callbacks that help developers with monitoring and give them some control over the training process.\n",
    "\n",
    "Callbacks are objects passed to *fit* functions executed in different points of training.\n",
    "\n",
    "There are many built-in callbacks, but you can implement your own as well.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a62ff4d",
   "metadata": {},
   "source": [
    "## Set up basis model for demonstration\n",
    "Load and process data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b733089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "COLUMN_NAMES = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    URL, \n",
    "    names=COLUMN_NAMES,\n",
    "    na_values='?', \n",
    "    sep=' ',\n",
    "    comment='\\t',  \n",
    "    skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13399e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    return (data-data.mean())/data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac = 0.8, random_state = 42)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3399e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d67d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = standardize(train_dataset)\n",
    "test_features = standardize(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ce1da",
   "metadata": {},
   "source": [
    "Define model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(7,))\n",
    "x = Dense(128, activation='relu')(input_layer)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output_layer = Dense(1)(x)\n",
    "model = Model(inputs = input_layer, outputs = output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(), metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9e93d",
   "metadata": {},
   "source": [
    "## ModelCheckpoint\n",
    "\n",
    "One of the most important callbacks - it can save progress after each epoch or track selected measure value and save only the best weights.\n",
    "\n",
    "https://keras.io/api/callbacks/model_checkpoint/\n",
    "\n",
    "Params:\n",
    "* *filepath* - where to save checkpoint(s), if it contains '{epoch}' it will save model after each epoch\n",
    "* *monitor* - metric to follow, you can add anything you want to from train log - loss, val_loss, custom metrics like val_mean_absolute_error...\n",
    "* *save_best_only* - if only the best model (measured by monitor) should be saved\n",
    "\n",
    "Target metric has to be set in model (in case you are not using just a simple loss).\n",
    "\n",
    "In case of using *val_* metrics you need to provide validation data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"checkpoints\",\n",
    "    monitor='val_mean_absolute_error',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff76b0d",
   "metadata": {},
   "source": [
    "## EarlyStopping\n",
    "\n",
    "Can stop training early when target metric has stopped improving.\n",
    "\n",
    "https://keras.io/api/callbacks/early_stopping/\n",
    "\n",
    "Params:\n",
    "* *monitor* - metric to follow, you can add anything you want to from train log - loss, val_loss, custom metrics like val_mean_absolute_error...\n",
    "* *patience* - number of epochs without improvement\n",
    "* *min_delta* - minimal change the will be considered as an improvement\n",
    "* *restore_best_weights* - if the best weights should be restored or just use the latest weights from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327c614",
   "metadata": {},
   "source": [
    "## CSVLogger\n",
    "\n",
    "Stream the training progress to the file.\n",
    "\n",
    "https://keras.io/api/callbacks/csv_logger/\n",
    "\n",
    "Params:\n",
    "* *filename* - Filename of the CSV file, e.g. 'run/log.csv'.\n",
    "* *separator* - String used to separate elements in the CSV file.\n",
    "* *append* - Boolean. True: append if file exists (useful for continuing training). False: overwrite existing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f132a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = keras.callbacks.CSVLogger('train.log', separator=',', append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32fc3e",
   "metadata": {},
   "source": [
    "## Generic Callback\n",
    "\n",
    "If you need some custom calls, you can use Callback with multiple prepared functions to implement:\n",
    "* on_batch_begin\n",
    "* on_batch_end\n",
    "* on_epoch_begin\n",
    "* ...\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback\n",
    "\n",
    "Data about training are provided in *logs* parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8542d",
   "metadata": {},
   "source": [
    "## Setting callbacks to model\n",
    "\n",
    "Callbacks are set fit function.\n",
    "\n",
    "In case of mutliple callbacks we can put them into List and set the List into the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc300d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    model_checkpoint,\n",
    "    early_stopping,\n",
    "    csv_logger\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614f76c",
   "metadata": {},
   "source": [
    "Use set callbacks and run training for 700 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03982aaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size = 16,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, \n",
    "    callbacks=callbacks_list,\n",
    "    epochs=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4114442",
   "metadata": {},
   "source": [
    "Thaks to early stopping callback interrupts training right before overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f26973",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0,10)\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50714ce0",
   "metadata": {},
   "source": [
    "## Changing learning rate dynamically\n",
    "\n",
    "Changing learning rate over the training.\n",
    "\n",
    "Optimizers like Adam do not used this technique very often since it can scale gradients in some degree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1b1eb",
   "metadata": {},
   "source": [
    "## LearningRateScheduler\n",
    "\n",
    "Allows users to set custom learning rate decay.\n",
    "\n",
    "https://keras.io/api/callbacks/learning_rate_scheduler/\n",
    "\n",
    "Demonstrations of different learning rates works better on more complicated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_images[:10000] / 255.0, train_labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(28, 28))\n",
    "x = Flatten()(input_layer)\n",
    "x = Dense(300, activation='relu')(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "output_layer = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs = input_layer, outputs = output_layer)\n",
    "model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), \n",
    "            loss='sparse_categorical_crossentropy', \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b21e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=20, \n",
    "    validation_split=0.2, \n",
    "    batch_size=64, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0,1.5)\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501e1d8",
   "metadata": {},
   "source": [
    "Set up base model for learning rate scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_layer = Input(shape=(28, 28))\n",
    "    x = Flatten()(input_layer)\n",
    "    x = Dense(300, activation='relu')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_layer = Dense(10, activation='softmax')(x)\n",
    "    model = Model(inputs = input_layer, outputs = output_layer)\n",
    "    model.compile(\n",
    "            optimizer='sgd', \n",
    "            loss='sparse_categorical_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac726843",
   "metadata": {},
   "source": [
    "### Exponencial scheduling\n",
    "\n",
    "Gradually drops the learning rate - in this modification by factor 10 every s epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43083138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay(lr0 = 0.1, s = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8634079",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=20, \n",
    "    validation_split=0.2, \n",
    "    batch_size=64, \n",
    "    verbose=1,\n",
    "    callbacks=[lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeb176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['lr'])\n",
    "plt.title('Learning rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d4583",
   "metadata": {},
   "source": [
    "Thanks to lowering learning rate model converges faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33414cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0,1.5)\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b6c4d",
   "metadata": {},
   "source": [
    "## Piecewise Constant Scheduling\n",
    "\n",
    "Use different constant learning rate for different numbers of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20146336",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant():\n",
    "    def piecewise_constant_fn(epoch):\n",
    "            if epoch < 5:\n",
    "                return 0.01\n",
    "            elif epoch < 15:\n",
    "                return 0.005\n",
    "            else:\n",
    "                return 0.001\n",
    "    return piecewise_constant_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c0c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=20, \n",
    "    validation_split=0.2, \n",
    "    batch_size=64, \n",
    "    verbose=1,\n",
    "    callbacks=[lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bedf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['lr'])\n",
    "plt.title('Learning rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09577159",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0,1.5)\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46789b",
   "metadata": {},
   "source": [
    "## ReduceLROnPlateau\n",
    "\n",
    "Reduce learning rate when metric stops improving.\n",
    "\n",
    "Params:\n",
    "* *monitor* - metric to follow\n",
    "* *patience* - number of epochs without improvement\n",
    "* *factor* - factor for reducing learning rate\n",
    "\n",
    "https://keras.io/api/callbacks/reduce_lr_on_plateau/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default metric is \"val_loss\"\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(28, 28))\n",
    "x = Flatten()(input_layer)\n",
    "x = Dense(300, activation='relu')(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "output_layer = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs = input_layer, outputs = output_layer)\n",
    "model.compile(\n",
    "    # start with high learning rate\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.1), \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=25,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['lr'])\n",
    "plt.title('Learning rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0,1.5)\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac9d770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
